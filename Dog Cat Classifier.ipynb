{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10158.jpg\n",
      "10401.jpg\n",
      "10747.jpg\n",
      "10797.jpg\n",
      "11410.jpg\n",
      "11675.jpg\n",
      "11702.jpg\n",
      "11849.jpg\n",
      "11853.jpg\n",
      "1308.jpg\n",
      "1866.jpg\n",
      "2384.jpg\n",
      "2688.jpg\n",
      "2877.jpg\n",
      "3136.jpg\n",
      "3288.jpg\n",
      "3588.jpg\n",
      "5604.jpg\n",
      "5736.jpg\n",
      "7112.jpg\n",
      "7133.jpg\n",
      "7369.jpg\n",
      "7459.jpg\n",
      "7969.jpg\n",
      "8730.jpg\n",
      "9188.jpg\n",
      "Thumbs.db\n"
     ]
    }
   ],
   "source": [
    "dogPath = './PetImages/Train/Dog'\n",
    "\n",
    "for p in os.listdir(dogPath):\n",
    "    try:\n",
    "        img_array = cv2.imread(os.path.join(dogPath, p), cv2.IMREAD_GRAYSCALE)\n",
    "        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "        X.append(new_img_array)\n",
    "        y.append(1)\n",
    "    except Exception as e:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10125.jpg\n",
      "10404.jpg\n",
      "10501.jpg\n",
      "10820.jpg\n",
      "11210.jpg\n",
      "11565.jpg\n",
      "11874.jpg\n",
      "11935.jpg\n",
      "140.jpg\n",
      "2663.jpg\n",
      "3300.jpg\n",
      "3491.jpg\n",
      "660.jpg\n",
      "666.jpg\n",
      "7968.jpg\n",
      "7978.jpg\n",
      "8470.jpg\n",
      "850.jpg\n",
      "9171.jpg\n",
      "936.jpg\n",
      "9565.jpg\n",
      "9778.jpg\n",
      "Thumbs.db\n"
     ]
    }
   ],
   "source": [
    "catPath = './PetImages/Train/Cat'\n",
    "\n",
    "for p in os.listdir(catPath):\n",
    "    try:\n",
    "        img_array = cv2.imread(os.path.join(catPath, p), cv2.IMREAD_GRAYSCALE)\n",
    "        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "        X.append(new_img_array)\n",
    "        y.append(0)\n",
    "    except Exception as e:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, 80,80,1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26311, 80, 80, 1)\n",
      "(26311, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu', input_shape = X.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21048 samples, validate on 5263 samples\n",
      "Epoch 1/7\n",
      "21048/21048 [==============================] - 79s 4ms/step - loss: 0.5023 - acc: 0.7659 - val_loss: 1.2234 - val_acc: 0.2721\n",
      "Epoch 2/7\n",
      "21048/21048 [==============================] - 72s 3ms/step - loss: 0.4140 - acc: 0.8154 - val_loss: 1.1429 - val_acc: 0.3492\n",
      "Epoch 3/7\n",
      "21048/21048 [==============================] - 54s 3ms/step - loss: 0.3714 - acc: 0.8369 - val_loss: 0.6634 - val_acc: 0.6789\n",
      "Epoch 4/7\n",
      "21048/21048 [==============================] - 26s 1ms/step - loss: 0.3298 - acc: 0.8588 - val_loss: 1.0120 - val_acc: 0.5408\n",
      "Epoch 5/7\n",
      "21048/21048 [==============================] - 27s 1ms/step - loss: 0.2793 - acc: 0.8860 - val_loss: 0.7374 - val_acc: 0.6945\n",
      "Epoch 6/7\n",
      "21048/21048 [==============================] - 26s 1ms/step - loss: 0.2239 - acc: 0.9099 - val_loss: 0.8015 - val_acc: 0.7038\n",
      "Epoch 7/7\n",
      "21048/21048 [==============================] - 26s 1ms/step - loss: 0.1707 - acc: 0.9323 - val_loss: 1.1444 - val_acc: 0.6318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f62e833c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=7, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "model.save('./Weights/dogCatClassifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
