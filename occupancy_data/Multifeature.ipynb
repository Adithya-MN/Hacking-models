{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datatraining.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns= ['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Light     CO2  HumidityRatio  Occupancy\n",
       "1        23.18   27.2720  426.0  721.25       0.004793          1\n",
       "2        23.15   27.2675  429.5  714.00       0.004783          1\n",
       "3        23.15   27.2450  426.0  713.50       0.004779          1\n",
       "4        23.15   27.2000  426.0  708.25       0.004772          1\n",
       "5        23.10   27.2000  426.0  704.50       0.004757          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8143 entries, 1 to 8143\n",
      "Data columns (total 6 columns):\n",
      "Temperature      8143 non-null float64\n",
      "Humidity         8143 non-null float64\n",
      "Light            8143 non-null float64\n",
      "CO2              8143 non-null float64\n",
      "HumidityRatio    8143 non-null float64\n",
      "Occupancy        8143 non-null int64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 445.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.619084</td>\n",
       "      <td>25.731507</td>\n",
       "      <td>119.519375</td>\n",
       "      <td>606.546243</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.212330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.016916</td>\n",
       "      <td>5.531211</td>\n",
       "      <td>194.755805</td>\n",
       "      <td>314.320877</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.408982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>16.745000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>412.750000</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.700000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.390000</td>\n",
       "      <td>26.222500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>453.500000</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.390000</td>\n",
       "      <td>30.533333</td>\n",
       "      <td>256.375000</td>\n",
       "      <td>638.833333</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.180000</td>\n",
       "      <td>39.117500</td>\n",
       "      <td>1546.333333</td>\n",
       "      <td>2028.500000</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature     Humidity        Light          CO2  HumidityRatio  \\\n",
       "count  8143.000000  8143.000000  8143.000000  8143.000000    8143.000000   \n",
       "mean     20.619084    25.731507   119.519375   606.546243       0.003863   \n",
       "std       1.016916     5.531211   194.755805   314.320877       0.000852   \n",
       "min      19.000000    16.745000     0.000000   412.750000       0.002674   \n",
       "25%      19.700000    20.200000     0.000000   439.000000       0.003078   \n",
       "50%      20.390000    26.222500     0.000000   453.500000       0.003801   \n",
       "75%      21.390000    30.533333   256.375000   638.833333       0.004352   \n",
       "max      23.180000    39.117500  1546.333333  2028.500000       0.006476   \n",
       "\n",
       "         Occupancy  \n",
       "count  8143.000000  \n",
       "mean      0.212330  \n",
       "std       0.408982  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(data.columns)\n",
    "cols.remove('Occupancy')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X1 = pd.DataFrame(scaler.fit_transform(X), columns=cols)\n",
    "Y = data['Occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X1.join(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data.columns:\n",
    "    train_data.fillna(method='bfill', inplace=True)\n",
    "    train_data.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    6414\n",
       "1.0    1729\n",
       "Name: Occupancy, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Occupancy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(5, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "classifierModel.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.3435 - acc: 0.8913 - val_loss: 0.2522 - val_acc: 0.8999\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2087 - acc: 0.9279 - val_loss: 0.2503 - val_acc: 0.9048\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1697 - acc: 0.9435 - val_loss: 0.2068 - val_acc: 0.9153\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1797 - acc: 0.9382 - val_loss: 0.2099 - val_acc: 0.9177\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1466 - acc: 0.9527 - val_loss: 0.2380 - val_acc: 0.9214\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1447 - acc: 0.9531 - val_loss: 0.2031 - val_acc: 0.9208\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1439 - acc: 0.9540 - val_loss: 0.2127 - val_acc: 0.9282\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1352 - acc: 0.9574 - val_loss: 0.2144 - val_acc: 0.9263\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1409 - acc: 0.9580 - val_loss: 0.2096 - val_acc: 0.9343\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1422 - acc: 0.9573 - val_loss: 0.1845 - val_acc: 0.9337\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1413 - acc: 0.9579 - val_loss: 0.1821 - val_acc: 0.9282\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1324 - acc: 0.9595 - val_loss: 0.1834 - val_acc: 0.9257\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1226 - acc: 0.9614 - val_loss: 0.1749 - val_acc: 0.9355\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1339 - acc: 0.9591 - val_loss: 0.1848 - val_acc: 0.9319\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1234 - acc: 0.9631 - val_loss: 0.1730 - val_acc: 0.9331\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1238 - acc: 0.9650 - val_loss: 0.1631 - val_acc: 0.9405\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1178 - acc: 0.9656 - val_loss: 0.1620 - val_acc: 0.9429\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1152 - acc: 0.9675 - val_loss: 0.1493 - val_acc: 0.9503\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1147 - acc: 0.9647 - val_loss: 0.1488 - val_acc: 0.9405\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1096 - acc: 0.9696 - val_loss: 0.1427 - val_acc: 0.9515\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1073 - acc: 0.9684 - val_loss: 0.1376 - val_acc: 0.9503\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1037 - acc: 0.9724 - val_loss: 0.1632 - val_acc: 0.9472\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1077 - acc: 0.9711 - val_loss: 0.1460 - val_acc: 0.9527\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1005 - acc: 0.9736 - val_loss: 0.1289 - val_acc: 0.9533\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1021 - acc: 0.9730 - val_loss: 0.1521 - val_acc: 0.9546\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0955 - acc: 0.9756 - val_loss: 0.1381 - val_acc: 0.9533\n",
      "Epoch 27/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0981 - acc: 0.9754 - val_loss: 0.1373 - val_acc: 0.9589\n",
      "Epoch 28/100\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.1077 - acc: 0.9724 - val_loss: 0.1372 - val_acc: 0.9583\n",
      "Epoch 29/100\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.0918 - acc: 0.9757 - val_loss: 0.1524 - val_acc: 0.9558\n",
      "Epoch 30/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0975 - acc: 0.9736 - val_loss: 0.1438 - val_acc: 0.9626\n",
      "Epoch 31/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0997 - acc: 0.9727 - val_loss: 0.1311 - val_acc: 0.9607\n",
      "Epoch 32/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0963 - acc: 0.9744 - val_loss: 0.1193 - val_acc: 0.9601\n",
      "Epoch 33/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0944 - acc: 0.9744 - val_loss: 0.1461 - val_acc: 0.9638\n",
      "Epoch 34/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1010 - acc: 0.9734 - val_loss: 0.1444 - val_acc: 0.9454\n",
      "Epoch 35/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0905 - acc: 0.9754 - val_loss: 0.1476 - val_acc: 0.9466\n",
      "Epoch 36/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0889 - acc: 0.9773 - val_loss: 0.1391 - val_acc: 0.9509\n",
      "Epoch 37/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0918 - acc: 0.9754 - val_loss: 0.1454 - val_acc: 0.9521\n",
      "Epoch 38/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0889 - acc: 0.9753 - val_loss: 0.1547 - val_acc: 0.9441\n",
      "Epoch 39/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0938 - acc: 0.9740 - val_loss: 0.1465 - val_acc: 0.9454\n",
      "Epoch 40/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0895 - acc: 0.9751 - val_loss: 0.1346 - val_acc: 0.9613\n",
      "Epoch 41/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0923 - acc: 0.9733 - val_loss: 0.1406 - val_acc: 0.9490\n",
      "Epoch 42/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0871 - acc: 0.9762 - val_loss: 0.1766 - val_acc: 0.9349\n",
      "Epoch 43/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0855 - acc: 0.9762 - val_loss: 0.1876 - val_acc: 0.9540\n",
      "Epoch 44/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0874 - acc: 0.9750 - val_loss: 0.1475 - val_acc: 0.9460\n",
      "Epoch 45/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0934 - acc: 0.9736 - val_loss: 0.1364 - val_acc: 0.9546\n",
      "Epoch 46/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0885 - acc: 0.9751 - val_loss: 0.1544 - val_acc: 0.9441\n",
      "Epoch 47/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0926 - acc: 0.9745 - val_loss: 0.1479 - val_acc: 0.9448\n",
      "Epoch 48/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0913 - acc: 0.9747 - val_loss: 0.1621 - val_acc: 0.9423\n",
      "Epoch 49/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0879 - acc: 0.9751 - val_loss: 0.1776 - val_acc: 0.9337\n",
      "Epoch 50/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0927 - acc: 0.9737 - val_loss: 0.1539 - val_acc: 0.9435\n",
      "Epoch 51/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0945 - acc: 0.9740 - val_loss: 0.1703 - val_acc: 0.9355\n",
      "Epoch 52/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0878 - acc: 0.9751 - val_loss: 0.1599 - val_acc: 0.9417\n",
      "Epoch 53/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0888 - acc: 0.9745 - val_loss: 0.1517 - val_acc: 0.9435\n",
      "Epoch 54/100\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.0809 - acc: 0.9765 - val_loss: 0.1602 - val_acc: 0.9417\n",
      "Epoch 55/100\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.0805 - acc: 0.9776 - val_loss: 0.1668 - val_acc: 0.9392\n",
      "Epoch 56/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0835 - acc: 0.9753 - val_loss: 0.1436 - val_acc: 0.9460\n",
      "Epoch 57/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0896 - acc: 0.9737 - val_loss: 0.1716 - val_acc: 0.9349\n",
      "Epoch 58/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0777 - acc: 0.9780 - val_loss: 0.1940 - val_acc: 0.9325\n",
      "Epoch 59/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0874 - acc: 0.9760 - val_loss: 0.1824 - val_acc: 0.9312\n",
      "Epoch 60/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0802 - acc: 0.9771 - val_loss: 0.1932 - val_acc: 0.9276\n",
      "Epoch 61/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0932 - acc: 0.9734 - val_loss: 0.1842 - val_acc: 0.9263\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0918 - acc: 0.9736 - val_loss: 0.1977 - val_acc: 0.9251\n",
      "Epoch 63/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0937 - acc: 0.9733 - val_loss: 0.1947 - val_acc: 0.9257\n",
      "Epoch 64/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0906 - acc: 0.9734 - val_loss: 0.1767 - val_acc: 0.9282\n",
      "Epoch 65/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0810 - acc: 0.9757 - val_loss: 0.2093 - val_acc: 0.9245\n",
      "Epoch 66/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0898 - acc: 0.9737 - val_loss: 0.1885 - val_acc: 0.9269\n",
      "Epoch 67/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0790 - acc: 0.9771 - val_loss: 0.1829 - val_acc: 0.9288\n",
      "Epoch 68/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0905 - acc: 0.9733 - val_loss: 0.2205 - val_acc: 0.9227\n",
      "Epoch 69/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0881 - acc: 0.9754 - val_loss: 0.1846 - val_acc: 0.9257\n",
      "Epoch 70/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0859 - acc: 0.9742 - val_loss: 0.1891 - val_acc: 0.9257\n",
      "Epoch 71/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0916 - acc: 0.9728 - val_loss: 0.1957 - val_acc: 0.9245\n",
      "Epoch 72/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0797 - acc: 0.9763 - val_loss: 0.1840 - val_acc: 0.9276\n",
      "Epoch 73/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0911 - acc: 0.9728 - val_loss: 0.2256 - val_acc: 0.9227\n",
      "Epoch 74/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0837 - acc: 0.9757 - val_loss: 0.1955 - val_acc: 0.9257\n",
      "Epoch 75/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0895 - acc: 0.9727 - val_loss: 0.2072 - val_acc: 0.9227\n",
      "Epoch 76/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0806 - acc: 0.9763 - val_loss: 0.1656 - val_acc: 0.9294\n",
      "Epoch 77/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0822 - acc: 0.9762 - val_loss: 0.1828 - val_acc: 0.9257\n",
      "Epoch 78/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0884 - acc: 0.9727 - val_loss: 0.2520 - val_acc: 0.9208\n",
      "Epoch 79/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0824 - acc: 0.9753 - val_loss: 0.2192 - val_acc: 0.9227\n",
      "Epoch 80/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0848 - acc: 0.9754 - val_loss: 0.1742 - val_acc: 0.9251\n",
      "Epoch 81/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0788 - acc: 0.9763 - val_loss: 0.2685 - val_acc: 0.9153\n",
      "Epoch 82/100\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.0838 - acc: 0.9747 - val_loss: 0.2589 - val_acc: 0.9165\n",
      "Epoch 83/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0848 - acc: 0.9759 - val_loss: 0.2342 - val_acc: 0.9165\n",
      "Epoch 84/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0843 - acc: 0.9763 - val_loss: 0.2284 - val_acc: 0.9153\n",
      "Epoch 85/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0795 - acc: 0.9774 - val_loss: 0.2043 - val_acc: 0.9214\n",
      "Epoch 86/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0816 - acc: 0.9754 - val_loss: 0.2433 - val_acc: 0.9153\n",
      "Epoch 87/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.2176 - val_acc: 0.9153\n",
      "Epoch 88/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0866 - acc: 0.9756 - val_loss: 0.2259 - val_acc: 0.9165\n",
      "Epoch 89/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0889 - acc: 0.9737 - val_loss: 0.2431 - val_acc: 0.9116\n",
      "Epoch 90/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0814 - acc: 0.9760 - val_loss: 0.2188 - val_acc: 0.9177\n",
      "Epoch 91/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0838 - acc: 0.9747 - val_loss: 0.2199 - val_acc: 0.9177\n",
      "Epoch 92/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0800 - acc: 0.9748 - val_loss: 0.2419 - val_acc: 0.9153\n",
      "Epoch 93/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0872 - acc: 0.9725 - val_loss: 0.2298 - val_acc: 0.9079\n",
      "Epoch 94/100\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0839 - acc: 0.9753 - val_loss: 0.2304 - val_acc: 0.9128\n",
      "Epoch 95/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0849 - acc: 0.9747 - val_loss: 0.2296 - val_acc: 0.9153\n",
      "Epoch 96/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0807 - acc: 0.9760 - val_loss: 0.3040 - val_acc: 0.9036\n",
      "Epoch 97/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0842 - acc: 0.9756 - val_loss: 0.2551 - val_acc: 0.9061\n",
      "Epoch 98/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0833 - acc: 0.9740 - val_loss: 0.1846 - val_acc: 0.9214\n",
      "Epoch 99/100\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0845 - acc: 0.9748 - val_loss: 0.2505 - val_acc: 0.9085\n",
      "Epoch 100/100\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 0.0847 - acc: 0.9733 - val_loss: 0.2228 - val_acc: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9499959dd8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierModel.fit(np.reshape(train_data[cols].values.astype(np.float64), newshape=(-1,5)), \n",
    "                    np.reshape(train_data['Occupancy'].values.astype(np.int64), newshape=(-1,1)),\n",
    "                    epochs=100, batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2665.000000</td>\n",
       "      <td>2665.000000</td>\n",
       "      <td>2665.000000</td>\n",
       "      <td>2665.000000</td>\n",
       "      <td>2665.000000</td>\n",
       "      <td>2665.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.801288</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.378488</td>\n",
       "      <td>0.354310</td>\n",
       "      <td>0.193016</td>\n",
       "      <td>0.364728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.010985</td>\n",
       "      <td>0.440589</td>\n",
       "      <td>1.284821</td>\n",
       "      <td>0.931213</td>\n",
       "      <td>0.716400</td>\n",
       "      <td>0.481444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.412137</td>\n",
       "      <td>-0.656589</td>\n",
       "      <td>-0.613726</td>\n",
       "      <td>-0.569664</td>\n",
       "      <td>-0.656114</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.030404</td>\n",
       "      <td>-0.446857</td>\n",
       "      <td>-0.613726</td>\n",
       "      <td>-0.447170</td>\n",
       "      <td>-0.390747</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.266426</td>\n",
       "      <td>-0.132259</td>\n",
       "      <td>-0.613726</td>\n",
       "      <td>-0.082870</td>\n",
       "      <td>-0.055659</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.708783</td>\n",
       "      <td>0.203433</td>\n",
       "      <td>1.658490</td>\n",
       "      <td>1.112903</td>\n",
       "      <td>0.784987</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.726444</td>\n",
       "      <td>1.037991</td>\n",
       "      <td>8.101569</td>\n",
       "      <td>2.531657</td>\n",
       "      <td>1.777883</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature     Humidity        Light          CO2  HumidityRatio  \\\n",
       "count  2665.000000  2665.000000  2665.000000  2665.000000    2665.000000   \n",
       "mean      0.801288    -0.068266     0.378488     0.354310       0.193016   \n",
       "std       1.010985     0.440589     1.284821     0.931213       0.716400   \n",
       "min      -0.412137    -0.656589    -0.613726    -0.569664      -0.656114   \n",
       "25%       0.030404    -0.446857    -0.613726    -0.447170      -0.390747   \n",
       "50%       0.266426    -0.132259    -0.613726    -0.082870      -0.055659   \n",
       "75%       1.708783     0.203433     1.658490     1.112903       0.784987   \n",
       "max       3.726444     1.037991     8.101569     2.531657       1.777883   \n",
       "\n",
       "         Occupancy  \n",
       "count  2665.000000  \n",
       "mean      0.364728  \n",
       "std       0.481444  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('datatest.csv')\n",
    "X_test = scaler.transform(test_data[cols])\n",
    "test_data[cols] = X_test\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11797135719446779, 0.9774859287054409]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierModel.evaluate(test_data[cols].values.astype(np.float64), test_data['Occupancy'].values.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel.save_weights('./classifierNNWeights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensor Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/tensor_forest/client/random_forest.py:130: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:428: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptquxgb0a\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f93fb56bb38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmptquxgb0a'}\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:509: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to the Estimator interface.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please feed input to tf.data to support dask.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please access pandas data directly.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please convert numpy dtypes explicitly.\n",
      "INFO:tensorflow:Constructing forest with params = \n",
      "INFO:tensorflow:{'num_trees': 50, 'max_nodes': 1000, 'bagging_fraction': 1.0, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 10, 'max_fertile_nodes': 0, 'split_after_samples': 250, 'valid_leaf_threshold': 1, 'dominate_method': 'bootstrap', 'dominate_fraction': 0.99, 'model_name': 'all_dense', 'split_finish_name': 'basic', 'split_pruning_name': 'none', 'collate_examples': False, 'checkpoint_stats': False, 'use_running_stats_method': False, 'initialize_average_splits': False, 'inference_tree_paths': False, 'param_file': None, 'split_name': 'less_or_equal', 'early_finish_check_every_samples': 0, 'prune_every_samples': 0, 'num_classes': 2, 'num_features': 5, 'regression': False, 'bagged_num_features': 5, 'bagged_features': None, 'num_outputs': 1, 'num_output_columns': 3, 'base_random_seed': 0, 'leaf_model_type': 0, 'stats_model_type': 0, 'finish_type': 0, 'pruning_type': 0, 'split_type': 0}\n",
      "INFO:tensorflow:dense_features_size: 5 dense: [{name: features original_type: 0 size: 5}] sparse: []\n",
      "INFO:tensorflow:dense_features_size: 5 dense: [{name: features original_type: 0 size: 5}] sparse: []\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmptquxgb0a/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 2.9334393, step = 1\n",
      "INFO:tensorflow:TensorForestLossHook resetting last_step.\n",
      "INFO:tensorflow:global_step/sec: 13.4237\n",
      "INFO:tensorflow:loss = 0.004688671, step = 101 (7.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8318\n",
      "INFO:tensorflow:loss = 0.0012959256, step = 201 (6.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7797\n",
      "INFO:tensorflow:loss = 0.000257569, step = 301 (5.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0812\n",
      "INFO:tensorflow:loss = 4.96034e-05, step = 401 (5.855 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 15.7195\n",
      "INFO:tensorflow:loss = 5.936504e-06, step = 501 (6.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2305\n",
      "INFO:tensorflow:loss = 3.4682662e-06, step = 601 (6.566 sec)\n",
      "INFO:tensorflow:TensorForestLossHook requesting stop.\n",
      "INFO:tensorflow:Saving checkpoints for 665 into /tmp/tmptquxgb0a/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:9: clean up resources: None\n",
      "INFO:tensorflow:Loss for final step: 3.4682648e-06.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorForestEstimator(params=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\n",
    "  num_classes=2, num_features=5, regression=False,\n",
    "  num_trees=50, max_nodes=1000)\n",
    "\n",
    "rfclassifier = \\\n",
    "tf.contrib.tensor_forest.client.random_forest.TensorForestEstimator(params)\n",
    "\n",
    "rfclassifier.fit(x=train_data[cols].values.astype('float32'), y=train_data['Occupancy'].values.astype('float32'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Constructing forest with params = \n",
      "INFO:tensorflow:{'num_trees': 50, 'max_nodes': 1000, 'bagging_fraction': 1.0, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 10, 'max_fertile_nodes': 0, 'split_after_samples': 250, 'valid_leaf_threshold': 1, 'dominate_method': 'bootstrap', 'dominate_fraction': 0.99, 'model_name': 'all_dense', 'split_finish_name': 'basic', 'split_pruning_name': 'none', 'collate_examples': False, 'checkpoint_stats': False, 'use_running_stats_method': False, 'initialize_average_splits': False, 'inference_tree_paths': False, 'param_file': None, 'split_name': 'less_or_equal', 'early_finish_check_every_samples': 0, 'prune_every_samples': 0, 'num_classes': 2, 'num_features': 5, 'regression': False, 'bagged_num_features': 5, 'bagged_features': None, 'num_outputs': 1, 'num_output_columns': 3, 'base_random_seed': 0, 'leaf_model_type': 0, 'stats_model_type': 0, 'finish_type': 0, 'pruning_type': 0, 'split_type': 0, 'params_proto': pruning_type {\n",
      "  prune_every_samples {\n",
      "    constant_value: 0.0\n",
      "  }\n",
      "}\n",
      "finish_type {\n",
      "  check_every_steps {\n",
      "    constant_value: 0.0\n",
      "  }\n",
      "}\n",
      "num_trees: 50\n",
      "max_nodes: 1000\n",
      "num_outputs: 2\n",
      "num_splits_to_consider {\n",
      "  constant_value: 10.0\n",
      "}\n",
      "split_after_samples {\n",
      "  constant_value: 250.0\n",
      "}\n",
      "dominate_fraction {\n",
      "  constant_value: 0.9900000095367432\n",
      "}\n",
      "num_features: 5\n",
      ", 'serialized_params_proto': b'\"\\x07\\n\\x05\\r\\x00\\x00\\x00\\x00*\\x07\\n\\x05\\r\\x00\\x00\\x00\\x00028\\xe8\\x07`\\x02j\\x05\\r\\x00\\x00 Ar\\x05\\r\\x00\\x00zCz\\x05\\r\\xa4p}?\\xa8\\x01\\x05'}\n",
      "INFO:tensorflow:dense_features_size: 5 dense: [{name: features original_type: 0 size: 5}] sparse: []\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptquxgb0a/model.ckpt-665\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "y_out = rfclassifier.predict(x=test_data[cols].values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(y_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'logits': array([-1.3862944], dtype=float32),\n",
       "  'logistic': array([0.2], dtype=float32),\n",
       "  'probabilities': array([0.8, 0.2], dtype=float32),\n",
       "  'classes': 0,\n",
       "  'prediction_variance': array([0.16000003, 0.16      ], dtype=float32)},\n",
       " {'logits': array([-0.66329414], dtype=float32),\n",
       "  'logistic': array([0.34], dtype=float32),\n",
       "  'probabilities': array([0.66      , 0.34000003], dtype=float32),\n",
       "  'classes': 0,\n",
       "  'prediction_variance': array([0.22440001, 0.2244    ], dtype=float32)},\n",
       " {'logits': array([-0.84729797], dtype=float32),\n",
       "  'logistic': array([0.29999998], dtype=float32),\n",
       "  'probabilities': array([0.70000005, 0.29999998], dtype=float32),\n",
       "  'classes': 0,\n",
       "  'prediction_variance': array([0.21000001, 0.21      ], dtype=float32)},\n",
       " {'logits': array([-1.1526796], dtype=float32),\n",
       "  'logistic': array([0.23999998], dtype=float32),\n",
       "  'probabilities': array([0.76, 0.24], dtype=float32),\n",
       "  'classes': 0,\n",
       "  'prediction_variance': array([0.18239999, 0.18239999], dtype=float32)},\n",
       " {'logits': array([-1.1526796], dtype=float32),\n",
       "  'logistic': array([0.23999998], dtype=float32),\n",
       "  'probabilities': array([0.76, 0.24], dtype=float32),\n",
       "  'classes': 0,\n",
       "  'prediction_variance': array([0.18239999, 0.18239999], dtype=float32)},\n",
       " {'logits': array([-0.66329414], dtype=float32),\n",
       "  'logistic': array([0.34], dtype=float32),\n",
       "  'probabilities': array([0.66      , 0.34000003], dtype=float32),\n",
       "  'classes': 0,\n",
       "  'prediction_variance': array([0.22440001, 0.2244    ], dtype=float32)},\n",
       " {'logits': array([0.24116203], dtype=float32),\n",
       "  'logistic': array([0.56], dtype=float32),\n",
       "  'probabilities': array([0.44, 0.56], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2464, 0.2464], dtype=float32)},\n",
       " {'logits': array([0.08004263], dtype=float32),\n",
       "  'logistic': array([0.52], dtype=float32),\n",
       "  'probabilities': array([0.48000002, 0.52      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2496, 0.2496], dtype=float32)},\n",
       " {'logits': array([0.4895482], dtype=float32),\n",
       "  'logistic': array([0.62], dtype=float32),\n",
       "  'probabilities': array([0.38, 0.62], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2356, 0.2356], dtype=float32)},\n",
       " {'logits': array([0.4895482], dtype=float32),\n",
       "  'logistic': array([0.62], dtype=float32),\n",
       "  'probabilities': array([0.38, 0.62], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2356, 0.2356], dtype=float32)},\n",
       " {'logits': array([0.32277328], dtype=float32),\n",
       "  'logistic': array([0.58], dtype=float32),\n",
       "  'probabilities': array([0.42000005, 0.58      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2436    , 0.24360001], dtype=float32)},\n",
       " {'logits': array([0.32277328], dtype=float32),\n",
       "  'logistic': array([0.58], dtype=float32),\n",
       "  'probabilities': array([0.42000005, 0.58      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2436    , 0.24360001], dtype=float32)},\n",
       " {'logits': array([0.32277328], dtype=float32),\n",
       "  'logistic': array([0.58], dtype=float32),\n",
       "  'probabilities': array([0.42000005, 0.58      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2436    , 0.24360001], dtype=float32)},\n",
       " {'logits': array([0.4895482], dtype=float32),\n",
       "  'logistic': array([0.62], dtype=float32),\n",
       "  'probabilities': array([0.38, 0.62], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2356, 0.2356], dtype=float32)},\n",
       " {'logits': array([0.9444614], dtype=float32),\n",
       "  'logistic': array([0.71999997], dtype=float32),\n",
       "  'probabilities': array([0.28000003, 0.71999997], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2016    , 0.20160002], dtype=float32)},\n",
       " {'logits': array([0.84729785], dtype=float32),\n",
       "  'logistic': array([0.7], dtype=float32),\n",
       "  'probabilities': array([0.3, 0.7], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.21      , 0.21000001], dtype=float32)},\n",
       " {'logits': array([1.0459685], dtype=float32),\n",
       "  'logistic': array([0.74], dtype=float32),\n",
       "  'probabilities': array([0.26, 0.74], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1924    , 0.19239998], dtype=float32)},\n",
       " {'logits': array([1.1526794], dtype=float32),\n",
       "  'logistic': array([0.76], dtype=float32),\n",
       "  'probabilities': array([0.24000001, 0.76      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.18239999, 0.18239999], dtype=float32)},\n",
       " {'logits': array([1.2656662], dtype=float32),\n",
       "  'logistic': array([0.78], dtype=float32),\n",
       "  'probabilities': array([0.22000003, 0.78      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1716    , 0.17160004], dtype=float32)},\n",
       " {'logits': array([1.6582279], dtype=float32),\n",
       "  'logistic': array([0.84000003], dtype=float32),\n",
       "  'probabilities': array([0.16000004, 0.84000003], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1344    , 0.13440001], dtype=float32)},\n",
       " {'logits': array([1.5163474], dtype=float32),\n",
       "  'logistic': array([0.82], dtype=float32),\n",
       "  'probabilities': array([0.18, 0.82], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1476, 0.1476], dtype=float32)},\n",
       " {'logits': array([1.0459685], dtype=float32),\n",
       "  'logistic': array([0.74], dtype=float32),\n",
       "  'probabilities': array([0.26, 0.74], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1924    , 0.19239998], dtype=float32)},\n",
       " {'logits': array([1.0459685], dtype=float32),\n",
       "  'logistic': array([0.74], dtype=float32),\n",
       "  'probabilities': array([0.26, 0.74], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1924    , 0.19239998], dtype=float32)},\n",
       " {'logits': array([1.0459685], dtype=float32),\n",
       "  'logistic': array([0.74], dtype=float32),\n",
       "  'probabilities': array([0.26, 0.74], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1924    , 0.19239998], dtype=float32)},\n",
       " {'logits': array([1.386294], dtype=float32),\n",
       "  'logistic': array([0.79999995], dtype=float32),\n",
       "  'probabilities': array([0.20000006, 0.79999995], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.16      , 0.16000003], dtype=float32)},\n",
       " {'logits': array([1.2656662], dtype=float32),\n",
       "  'logistic': array([0.78], dtype=float32),\n",
       "  'probabilities': array([0.22000003, 0.78      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1716    , 0.17160004], dtype=float32)},\n",
       " {'logits': array([1.2656662], dtype=float32),\n",
       "  'logistic': array([0.78], dtype=float32),\n",
       "  'probabilities': array([0.22000003, 0.78      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.1716    , 0.17160004], dtype=float32)},\n",
       " {'logits': array([0.9444614], dtype=float32),\n",
       "  'logistic': array([0.71999997], dtype=float32),\n",
       "  'probabilities': array([0.28000003, 0.71999997], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2016    , 0.20160002], dtype=float32)},\n",
       " {'logits': array([0.6632941], dtype=float32),\n",
       "  'logistic': array([0.66], dtype=float32),\n",
       "  'probabilities': array([0.34000003, 0.66      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2244    , 0.22440001], dtype=float32)},\n",
       " {'logits': array([0.9444614], dtype=float32),\n",
       "  'logistic': array([0.71999997], dtype=float32),\n",
       "  'probabilities': array([0.28000003, 0.71999997], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2016    , 0.20160002], dtype=float32)},\n",
       " {'logits': array([1.1526794], dtype=float32),\n",
       "  'logistic': array([0.76], dtype=float32),\n",
       "  'probabilities': array([0.24000001, 0.76      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.18239999, 0.18239999], dtype=float32)},\n",
       " {'logits': array([0.7537718], dtype=float32),\n",
       "  'logistic': array([0.68], dtype=float32),\n",
       "  'probabilities': array([0.32, 0.68], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.21759999, 0.21759999], dtype=float32)},\n",
       " {'logits': array([0.7537718], dtype=float32),\n",
       "  'logistic': array([0.68], dtype=float32),\n",
       "  'probabilities': array([0.32, 0.68], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.21759999, 0.21759999], dtype=float32)},\n",
       " {'logits': array([0.84729785], dtype=float32),\n",
       "  'logistic': array([0.7], dtype=float32),\n",
       "  'probabilities': array([0.3, 0.7], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.21      , 0.21000001], dtype=float32)},\n",
       " {'logits': array([0.9444614], dtype=float32),\n",
       "  'logistic': array([0.71999997], dtype=float32),\n",
       "  'probabilities': array([0.28000003, 0.71999997], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.2016    , 0.20160002], dtype=float32)},\n",
       " {'logits': array([1.1526794], dtype=float32),\n",
       "  'logistic': array([0.76], dtype=float32),\n",
       "  'probabilities': array([0.24000001, 0.76      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.18239999, 0.18239999], dtype=float32)},\n",
       " {'logits': array([1.1526794], dtype=float32),\n",
       "  'logistic': array([0.76], dtype=float32),\n",
       "  'probabilities': array([0.24000001, 0.76      ], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.18239999, 0.18239999], dtype=float32)},\n",
       " {'logits': array([1.386294], dtype=float32),\n",
       "  'logistic': array([0.79999995], dtype=float32),\n",
       "  'probabilities': array([0.20000006, 0.79999995], dtype=float32),\n",
       "  'classes': 1,\n",
       "  'prediction_variance': array([0.16      , 0.16000003], dtype=float32)}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array([i['probabilities'] for i in a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = [(i[0], i[1]) for i in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2665, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING NOISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN with Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_COEFF = 2.0\n",
    "MIS_COEFF = 1.0\n",
    "BATCH_SIZE = 80\n",
    "NUM_EPOCHS = 30\n",
    "modelHistory = {'reg_loss':[], 'miss_loss':[], 'values':[], 'noise':[], 'orig_labels':[],\\\n",
    "                'pred_labels':[], 'new_labels':[]}\n",
    "\n",
    "\n",
    "adversarialModel = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(5, activation=tf.nn.tanh)\n",
    "])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.cast(np.reshape(train_data[cols].values, newshape=(-1,5)), tf.float32),\n",
    "    tf.cast(np.reshape(train_data['Occupancy'].values, newshape=(-1,1)), tf.int64)))\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(80, 2)\n",
      "(80, 2)\n",
      "(80, 2)\n",
      "(80, 2)\n",
      "(80, 2)\n",
      "5\n",
      "(80, 2)\n",
      "6\n",
      "(80, 2)\n",
      "7\n",
      "(80, 2)\n",
      "8\n",
      "(80, 2)\n",
      "9\n",
      "(80, 2)\n",
      "10\n",
      "(80, 2)\n",
      "11\n",
      "(80, 2)\n",
      "12\n",
      "(80, 2)\n",
      "13\n",
      "(80, 2)\n",
      "14\n",
      "(80, 2)\n",
      "15\n",
      "(80, 2)\n",
      "16\n",
      "(80, 2)\n",
      "17\n",
      "(80, 2)\n",
      "18\n",
      "(80, 2)\n",
      "19\n",
      "(80, 2)\n",
      "20\n",
      "(80, 2)\n",
      "21\n",
      "(80, 2)\n",
      "22\n",
      "(80, 2)\n",
      "23\n",
      "(80, 2)\n",
      "24\n",
      "(80, 2)\n",
      "25\n",
      "(80, 2)\n",
      "26\n",
      "(80, 2)\n",
      "27\n",
      "(80, 2)\n",
      "28\n",
      "(80, 2)\n",
      "29\n",
      "(80, 2)\n",
      "30\n",
      "(80, 2)\n",
      "31\n",
      "(80, 2)\n",
      "32\n",
      "(25, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: The shape of labels (received (25,)) should equal the shape of logits except for the last dimension (received (80, 2)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-a7290d3e04b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mregTerm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREG_COEFF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             missTerm = tf.math.multiply(tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n\u001b[0;32m---> 20\u001b[0;31m                             tf.math.subtract(1, tf.argmax(pred_labels, axis=1)), new_labels)), MIS_COEFF)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregTerm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissTerm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    124\u001b[0m            'keras.losses.sparse_categorical_crossentropy')\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m   res = nn.sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 3632\u001b[0;31m       labels=targets, logits=logits)\n\u001b[0m\u001b[1;32m   3633\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     \u001b[0;31m# If our output includes timesteps or spatial dimensions we need to reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                        \u001b[0;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n\u001b[0;32m-> 2045\u001b[0;31m                                                      logits.get_shape()))\n\u001b[0m\u001b[1;32m   2046\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (25,)) should equal the shape of logits except for the last dimension (received (80, 2))."
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "iter = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(iter)\n",
    "    for (batch, (vals, orig_labels)) in enumerate(dataset.take(-1)):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            iter+=1\n",
    "#             pred_labels = classifierModel(vals)\n",
    "#             print(pred_labels.shape)\n",
    "            pred_labels = tf.convert_to_tensor(probs[iter*80:(iter+1)*80])\n",
    "            print(pred_labels.shape)\n",
    "#             pred\n",
    "#             print(pred_labels)\n",
    "            noise = adversarialModel(vals)\n",
    "            new_labels = classifierModel(tf.add(vals, noise))\n",
    "\n",
    "            regTerm = tf.math.multiply(tf.reduce_mean(tf.math.abs(noise)), REG_COEFF)\n",
    "            missTerm = tf.math.multiply(tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                            tf.math.subtract(1, tf.argmax(pred_labels, axis=1)), new_labels)), MIS_COEFF)\n",
    "\n",
    "            loss = tf.add(regTerm, missTerm)\n",
    "\n",
    "        grads = tape.gradient(loss, adversarialModel.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, adversarialModel.trainable_variables), global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            modelHistory['reg_loss'].append(regTerm.numpy())\n",
    "            modelHistory['miss_loss'].append(missTerm.numpy())\n",
    "            modelHistory['noise'].append(noise.numpy())\n",
    "            modelHistory['values'].append(vals.numpy())\n",
    "            modelHistory['orig_labels'].append(orig_labels.numpy())\n",
    "            modelHistory['pred_labels'].append(pred_labels.numpy())\n",
    "            modelHistory['new_labels'].append(new_labels.numpy())\n",
    "        if iter > 1:\n",
    "            temp1 = modelHistory['reg_loss'][-1] + modelHistory['miss_loss'][-1]\n",
    "            temp2 = modelHistory['reg_loss'][-2] + modelHistory['miss_loss'][-2]\n",
    "            if(abs(temp2 - temp1) < 1e-3 or iter > 4):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelHistory['reg_loss'])\n",
    "plt.plot(modelHistory['miss_loss'])\n",
    "plt.savefig('Plot-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "temp = np.asarray([train_data[cols].values\\\n",
    "                   [np.random.randint(low = 0, high=train_data.shape[0])].astype('float32')\n",
    "                   for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0795752 , -0.9097133 , -0.6137261 , -0.5410289 , -0.87276405],\n",
       "       [ 1.5768403 ,  0.02910802,  1.6867317 ,  0.537553  ,  0.5019205 ],\n",
       "       [ 0.42377406, -0.1611875 , -0.6137261 , -0.54421055, -0.04024421],\n",
       "       [ 1.1515088 , -0.98293865,  1.8972647 ,  0.6202761 , -0.6953054 ],\n",
       "       [-1.1005353 ,  0.22934772, -0.49048725, -0.5879584 , -0.0960639 ],\n",
       "       [-0.11710987, -0.7750148 , -0.6137261 , -0.54421055, -0.7870914 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp.shape)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_temp = np.asarray(adversarialModel(temp.reshape(-1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07132854,  0.10668082,  0.62216264,  0.97147983, -0.20473191],\n",
       "       [-0.12938182, -0.02969338,  0.67064196,  0.41345605,  0.38042086],\n",
       "       [-0.2074758 ,  0.04486365,  0.66836375,  0.9763742 , -0.4550676 ],\n",
       "       [-0.03284572,  0.03093785,  0.83426195, -0.05421574,  0.74733955],\n",
       "       [ 0.03263882,  0.01525571,  0.12281962,  0.98499537, -0.05386202],\n",
       "       [-0.05933964,  0.08230284,  0.5348388 ,  0.9741815 , -0.17105953]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 3.4001447e-11],\n",
       "       [1.0516195e-01, 8.9483804e-01],\n",
       "       [1.0000000e+00, 4.0157003e-10],\n",
       "       [7.1055539e-02, 9.2894447e-01],\n",
       "       [1.0000000e+00, 4.8073739e-10],\n",
       "       [1.0000000e+00, 4.5634718e-11]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierModel.predict(temp.reshape(-1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07424838, 0.9257517 ],\n",
       "       [0.4165192 , 0.58348083],\n",
       "       [0.04830322, 0.9516968 ],\n",
       "       [0.15432946, 0.84567046],\n",
       "       [0.16255286, 0.83744717],\n",
       "       [0.0880539 , 0.91194606]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierModel.predict(noisy_temp.reshape(-1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7850654298013233"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(modelHistory['reg_loss'])/len(modelHistory['reg_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8641845188945173"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(modelHistory['miss_loss'])/len(modelHistory['miss_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG_COEFF = 2.0\n",
    "MIS_COEFF = 1.0\n",
    "BATCH_SIZE = 80\n",
    "NUM_EPOCHS = 30\n",
    "modelHistory = {'reg_loss':[], 'miss_loss':[], 'values':[], 'noise':[], 'orig_labels':[],\\\n",
    "                'pred_labels':[], 'new_labels':[]}\n",
    "\n",
    "\n",
    "adversarialModel = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(5, activation=tf.nn.tanh)\n",
    "])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.cast(np.reshape(train_data[cols].values, newshape=(-1,5)), tf.float32),\n",
    "    tf.cast(np.reshape(train_data['Occupancy'].values, newshape=(-1,1)), tf.int64)))\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    for (batch, (vals, orig_labels)) in enumerate(dataset.take(-1)):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            y_out = list(rfclassifier.predict(x=vals.numpy()))\n",
    "            pred_labels = [i['probabilities'] for i in y_out]\n",
    "            noise = adversarialModel(vals)\n",
    "            new_labels = classifierModel(tf.add(vals, noise))\n",
    "\n",
    "            regTerm = tf.math.multiply(tf.reduce_mean(tf.math.abs(noise)), REG_COEFF)\n",
    "            missTerm = tf.math.multiply(tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                            tf.math.subtract(1, tf.argmax(pred_labels, axis=1)), new_labels)), MIS_COEFF)\n",
    "\n",
    "            loss = tf.add(regTerm, missTerm)\n",
    "\n",
    "        grads = tape.gradient(loss, adversarialModel.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, adversarialModel.trainable_variables), global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            modelHistory['reg_loss'].append(regTerm.numpy())\n",
    "            modelHistory['miss_loss'].append(missTerm.numpy())\n",
    "            modelHistory['noise'].append(noise.numpy())\n",
    "            modelHistory['values'].append(vals.numpy())\n",
    "            modelHistory['orig_labels'].append(orig_labels)\n",
    "            modelHistory['pred_labels'].append(pred_labels)\n",
    "            modelHistory['new_labels'].append(new_labels.numpy())\n",
    "        temp1 = modelHistory['reg_loss'][-1] + modelHistory['miss_loss'][-1]\n",
    "        temp2 = modelHistory['reg_loss'][-2] + modelHistory['miss_loss'][-2]\n",
    "        if(abs(temp2 - temp1) < 1e-3):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for (batch, (vals, orig_labels)) in enumerate(dataset.take(1)):\n",
    "    print(vals)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[cols].values.astype('float32').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
